import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any
from pydantic import ValidationError

from news_analyzer.models.data_models import NewsData, NewsItem


class NewsLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –∏ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä JSON —Ñ–∞–π–ª–æ–≤ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏"""

    def load_json(self, file_path: str) -> NewsData:
        """–ó–∞–≥—Ä—É–∑–∫–∞ JSON —Ñ–∞–π–ª–∞"""

        file_path = Path(file_path)

        if not file_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            return self._validate_news_data(data)

        except json.JSONDecodeError as e:
            raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON: {e}")
        except ValidationError as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")

    def _validate_news_data(self, data: Dict[str, Any]) -> NewsData:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è timestamp
        if isinstance(data.get('timestamp'), str):
            data['timestamp'] = datetime.fromisoformat(
                data['timestamp'].replace('Z', '+00:00')
            )

        news_items = []

        for news_dict in data.get('news', []):
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç
            if isinstance(news_dict.get('published_at'), str):
                news_dict['published_at'] = datetime.fromisoformat(
                    news_dict['published_at'].replace('Z', '+00:00')
                )

            if isinstance(news_dict.get('collected_at'), str):
                news_dict['collected_at'] = datetime.fromisoformat(
                    news_dict['collected_at'].replace('Z', '+00:00')
                )

            try:
                news_item = NewsItem(**news_dict)
                news_items.append(news_item)
            except ValidationError as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ {news_dict.get('id')}: {e}")
                continue

        return NewsData(timestamp=data['timestamp'], news=news_items)

    def create_sample_data(self, output_path: str):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""

        sample_data = {
            "timestamp": datetime.now().isoformat(),
            "news": [
                {
                    "id": "sample_1",
                    "source": "NewsAPI_bloomberg",
                    "source_credibility": 0.9,
                    "title": "–¶–ë –†–§ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–æ 21%",
                    "content": "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –†–æ—Å—Å–∏–∏ –ø—Ä–∏–Ω—è–ª —Ä–µ—à–µ–Ω–∏–µ –ø–æ–≤—ã—Å–∏—Ç—å –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É —Å 19% –¥–æ 21% –≥–æ–¥–æ–≤—ã—Ö. –†–µ—à–µ–Ω–∏–µ —Å—Ç–∞–ª–æ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–º –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ —Ä—ã–Ω–∫–∞. –ü–æ–≤—ã—à–µ–Ω–∏–µ —Å–≤—è–∑–∞–Ω–æ —Å —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º –∏–Ω—Ñ–ª—è—Ü–∏–∏ –∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å—é –æ—Ö–ª–∞–∂–¥–µ–Ω–∏—è —ç–∫–æ–Ω–æ–º–∏–∫–∏. –†—É–±–ª—å —É–∫—Ä–µ–ø–∏–ª—Å—è –Ω–∞ 2% –ø–æ—Å–ª–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è.",
                    "url": "https://bloomberg.com/news/cb-rate-increase",
                    "published_at": datetime.now().isoformat(),
                    "keywords": ["–¶–ë", "—Å—Ç–∞–≤–∫–∞", "–∏–Ω—Ñ–ª—è—Ü–∏—è", "—Ä—É–±–ª—å"],
                    "entities": ["–¶–ë –†–§", "–†–æ—Å—Å–∏—è", "—Ä—É–±–ª—å"],
                    "collected_at": datetime.now().isoformat(),
                    "dedup_hash": "hash_cb_rate",
                    "credibility_score": 0.85,
                    "confirmation_count": 3,
                    "duplicate_group": "cb_rate_oct2025"
                },
                {
                    "id": "sample_2",
                    "source": "NewsAPI_reuters",
                    "source_credibility": 0.95,
                    "title": "Apple –æ–±—ä—è–≤–∏–ª–∞ –æ –ø–æ–≥–ª–æ—â–µ–Ω–∏–∏ –ò–ò-—Å—Ç–∞—Ä—Ç–∞–ø–∞ –∑–∞ $5 –º–ª—Ä–¥",
                    "content": "–ö–æ–º–ø–∞–Ω–∏—è Apple –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞ –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ —Å—Ç–∞—Ä—Ç–∞–ø–∞ –≤ –æ–±–ª–∞—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∑–∞ 5 –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ –¥–æ–ª–ª–∞—Ä–æ–≤. –°–¥–µ–ª–∫–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞ —É–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –ø–æ–º–æ—â–Ω–∏–∫–æ–≤. –ê–∫—Ü–∏–∏ Apple –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 3% –ø–æ—Å–ª–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è.",
                    "url": "https://reuters.com/apple-ai-acquisition",
                    "published_at": datetime.now().isoformat(),
                    "keywords": ["Apple", "–ø–æ–≥–ª–æ—â–µ–Ω–∏–µ", "–ò–ò", "—Å—Ç–∞—Ä—Ç–∞–ø"],
                    "entities": ["Apple Inc.", "AAPL", "–°–®–ê"],
                    "collected_at": datetime.now().isoformat(),
                    "dedup_hash": "hash_apple_ai",
                    "credibility_score": 0.9,
                    "confirmation_count": 2,
                    "duplicate_group": "apple_ai_oct2025"
                }
            ]
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(sample_data, f, ensure_ascii=False, indent=2)

        print(f"üìù –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã: {output_path}")